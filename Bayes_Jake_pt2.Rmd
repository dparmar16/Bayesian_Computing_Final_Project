---
title: "Jake_Bayes_Project"
author: "Jake Lieberfarb"
date: "11/7/2021"
output: html_document
---


```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = 'markup', message = F)
knitr::opts_chunk$set(warning = F, results = 'hide', message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r basic, include=F}
# use this function to conveniently load libraries and work smoothly with knitting
# can add quietly=T option to the require() function
loadPkg = function(pkg, character.only = FALSE) { 
  if (!character.only) { pkg <- as.character(substitute(pkg)) }
  pkg <- ifelse(!character.only, as.character(substitute(pkg)) , pkg)  
  if (!require(pkg,character.only=T, quietly =T)) {  install.packages(substitute(pkg),dep=T); if(!require(pkg,character.only=T)) stop("Package not found") } 
}
loadPkg(knitr)

# unload/detact package when done using it
unloadPkg = function(pkg, character.only = FALSE) { 
  if(!character.only) { pkg <- as.character(substitute(pkg)) } 
  search_item <- paste("package", pkg,sep = ":") 
  while(search_item %in% search()) { detach(search_item, unload = TRUE, character.only = TRUE) } 
}
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
loadPkg(mltools)
loadPkg(data.table)
```

```{r}
#import necessary Linear model data
set.seed(42)
data_df <- read.csv("/Users/jakelieberfarb/Desktop/college/Grad (2021-2022)/Bayesian DS/Project/Bayesian_Computing_Final_Project/Linear_model_data.csv")
data_df$id <- sample(98439, size = nrow(data_df), replace = TRUE)
#data_df <- read.csv("/Users/jakelieberfarb/Desktop/college/Grad (2021-2022)/Bayesian DS/Project/uk_used_cars.csv")
#str(data)
#summary(data)
# 9353 NA values need to remove them 
#nrow(data) # 108540 rows with NA values
#data_clean <- data[complete.cases(data), ] # removes NA values, rename as 'data_clean'
#head(data_clean) # check to see if NA values are removed 
#nrow(data_clean) #99187 rows with no NA values 
#x <- (1-nrow(data_clean)/nrow(data))* 100
#x # 8.62% of the data had na values
drop <- c("X")
data_df = data_df[,!(names(data_df) %in% drop)]
head(data_df)
```


```{r}
#turn categorical values into numerics 
# data_clean_2 <- sapply(data_clean, unclass)
# df <- as.data.frame(data_clean_2)
# df$model <- as.factor(df$model)
# df$price <- as.factor(df$price)
# df$transmission <- as.factor(df$transmission)
# df$fuelType <- as.factor(df$fuelType)
# df$Car.Make <- as.factor(df$Car.Make)
# df$price <- as.numeric(df$price)
# head(df)
```




```{r}
# # categorical data correlation plot 
# data_clean_cat <- subset(df, select = c('model','price','transmission','fuelType','Car.Make'))
# # make categorical data numeric
# data_new_cat <- sapply(data_clean_cat, unclass)
# corr_cat <- round(cor(data_new_cat), 1) 
# p.mat_cat <- cor_pmat(corr_cat, method = 'spearman') # use Spearman correlation for large dataset of categorical features
# ggcorrplot(corr_cat, hc.order=TRUE,p.mat=p.mat_cat, lab = TRUE) + labs(title = "  Correlation Plot of Categorical data")

# cor(data_new_cat$price, data_new_cat$model,
#   method = "spearman"
# )

```



```{r}
# normalize Price 
# library(MASS)
# bc <- boxcox(data_clean$price ~ x)
# (lambda <- bc$x[which.max(bc$y)])
head(df)
```


```{r}
# Linear Regression Model
# qjaw <- lm(bone ~ age + I(age ^ 2), data = jaws)
# summary(qjaw)
# plot(jaws)
# grid <- seq(0, 60, 0.01)
# lines(grid, predict(qjaw, data.frame(age = grid)), col = "red")

#pick model from stepwise regression 
library(tidyverse)
library(caret)
library(leaps)
data_df$year_2008 <- as.factor(data_df$year_2008)
data_df$year_2009 <- as.factor(data_df$year_2009)
data_df$year_2010 <- as.factor(data_df$year_2010)
data_df$year_2011 <- as.factor(data_df$year_2011)
data_df$year_2012 <- as.factor(data_df$year_2012)
data_df$year_2013 <- as.factor(data_df$year_2013)
data_df$year_2014 <- as.factor(data_df$year_2014)
data_df$year_2015 <- as.factor(data_df$year_2015)
data_df$year_2016 <- as.factor(data_df$year_2016)
data_df$year_2017 <- as.factor(data_df$year_2017)
data_df$year_2018 <- as.factor(data_df$year_2018)
data_df$year_2019 <- as.factor(data_df$year_2019)
data_df$year_2020 <- as.factor(data_df$year_2020)
data_df$transmission_Automatic <- as.factor(data_df$transmission_Automatic)
data_df$transmission_Manual <- as.factor(data_df$transmission_Manual)
data_df$transmission_Semi.Auto <- as.factor(data_df$transmission_Semi.Auto)
data_df$fuelType_Diesel <- as.factor(data_df$fuelType_Diesel)
data_df$fuelType_Hybrid <- as.factor(data_df$fuelType_Hybrid)
data_df$fuelType_Petrol <- as.factor(data_df$fuelType_Petrol)
data_df$Car.Make_Audi <- as.factor(data_df$Car.Make_Audi)
data_df$Car.Make_BMW <- as.factor(data_df$Car.Make_BMW)
data_df$Car.Make_Ford <- as.factor(data_df$Car.Make_Ford)
data_df$Car.Make_Hyundai <- as.factor(data_df$Car.Make_Hyundai)
data_df$Car.Make_Mercedes <- as.factor(data_df$Car.Make_Mercedes)
data_df$Car.Make_Skoda <- as.factor(data_df$Car.Make_Skoda)
data_df$Car.Make_Toyota <- as.factor(data_df$Car.Make_Toyota)
data_df$Car.Make_Vauxhall <- as.factor(data_df$Car.Make_Vauxhall)
data_df$Car.Make_Volkswagen <- as.factor(data_df$Car.Make_Volkswagen)
# split linear data into train and test
smp_size <- floor(0.75 * nrow(data_df)) # 75/25 for train/test split 
# set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data_df)), size = smp_size)
train <- data_df[train_ind, ]
test <- data_df[-train_ind, ]
head(data_df)

```

```{r}
# need assistance fixing this
op <- par(oma=c(5,7,1,1))
pairs(data)
par(op)

#quick descriptive stats on price value
ybar<- mean(data_df$price)
std <- sd(data_df$price)
s2  <- var(data_df$price)
n   <- length(data_df$price)
descriptive <- c(n,ybar,std,s2)
names(descriptive) <- c("N","Ybar","std","s^2")
descriptive


```








```{r}
# built full LM frequentist model
model_full <- lm(price~. , data = train)
summary(model_full)
model_full_vif = faraway::vif(model_full)
#none of the coefficients have a significantly high vif factor
model_full_vif
#names(model_full)
```

```{r}
#loadPkg(BAS)
# Obtain residuals and n
#still not working
test_x <- test[, !names(test) %in% c("price")] 
y_pred= predict(model_full, test_x)

resid= test$price-y_pred
n = length(resid)
# Calculate MSE
MSE = 1/ (n - 2) * sum((resid ^ 2))
options(digits=15) # make sure MSE is listed out completely
print('MSE is')
MSE
plot(resid_full, x_lab= 'MSE', main='residual plot of model')
par(mfrow = c(2, 2))
plot(model_full)
```

```{r}
#R^2 model
loadPkg("leaps")
visbest_adjr <- regsubsets(price~. , data = data_df, nbest = 2, method = "exhaustive",really.big=T) 
plot(visbest_adjr, scale = "adjr2", main = "Adjusted R^2")
summaryRegForward = summary(visbest_adjr)
#r_sqr_model <- lm(price~ year+transmission+mileage+engineSize+Car.Make, data = df)
#summary(r_sqr_model)
#resid_r_sqr = residuals(r_sqr_model)
#n = length(resid_r_sqr)

# Calculate MSE
#MSE = 1/ (n - 2) * sum((resid_r_sqr ^ 2))
#print('MSE for frequentist r^2 is')
#MSE
#plot(resid_r_sqr)
```

```{r}
#built adjusted R^2 model 
# issue here bc when I built the model based off the ideal adj R^2 model it returned a much lower adjr^2 value
adj_model <- lm(price~ year_2018+year_2019+transmission_Automatic+mileage+fuelType_Hybrid+fuelType_Petrol+
                   Car.Make_Ford+Car.Make_Hyundai+Car.Make_Vauxhall , data = data_df)
summary(adj_model)
adj_model_vif = faraway::vif(adj_model)
#none of the coefficients have a significantly high vif factor
adj_model_vif
```



```{r}
# Standardize data
train_2 <- train %>% mutate_at(c("price", "mileage", "tax", "mpg", "engineSize" ), ~(scale(.) %>% as.vector))
head(train_2)
```

```{r}
# jags model 
library(rjags)
dataList <- list(
         y=train$price,
                  y_2008=train$year_2008,
                  y_2009=train$year_2009,
                  y_2010=train$year_2010,
                  y_2011=train$year_2011,
                  y_2012=train$year_2012,
                  y_2013=train$year_2013,
                  y_2014=train$year_2014,
                  y_2015=train$year_2015,
                  y_2016=train$year_2016,
                  y_2017=train$year_2017,
                  y_2018=train$year_2018,
                  y_2019=train$year_2019,
                  y_2020=train$year_2020,
                  TA=train$transmission_Automatic,
                  TM=train$transmission_Manual,
                  TS=train$transmission_Semi.Auto,
                  mileage=train$mileage,
                  FTD=train$fuelType_Diesel,
                  FTH=train$fuelType_Hybrid,
                  FTP=train$fuelType_Petrol,
                  tax=train$tax,
                  mpg=train$mpg,
                  ES=train$engineSize,
                  CMA=train$Car.Make_Audi,
                  CMB=train$Car.Make_BMW,
                  CMF=train$Car.Make_Ford,
                  CMH=train$Car.Make_Hyundai,
                  CMM=train$Car.Make_Mercedes,
                  CMS=train$Car.Make_Skoda,
                  CMT=train$Car.Make_Toyota,
                  CMVA=train$Car.Make_Vauxhall,
                  CMVO=train$Car.Make_Volkswagen,
                 N=length(train$price),
                 sdY = sd(train$price)
                 )
```


```{r}
model_1 <- "model{
  for(i in 1:N){
      mu[i] = b0 + b1 * y_2008[i] + b2 * y_2009[i] +b3*y_2010[i]+ b4* y_2011[i] + b5*y_2012[i]  + b6 * y_2013[i] +
      b7* y_2014[i] + b8*y_2015[i] + b9* y_2016[i] + b10 * y_2017[i] + b11*y_2018[i]
    + b12*y_2019[i] + b13*y_2020[i] + b14*TA[i] + b15*TM[i] + b16*TS[i]
    + b17*mileage[i] + b18*FTD[i] + b19*FTH[i] + b20*FTP[i] + b21*tax[i] 
    + b22*mpg[i] + b23*ES[i] + b24*CMA[i] + b25*CMB[i] + b26*CMF[i] + b27*CMH[i] 
    + b28*CMM[i] + b29*CMS[i] + b30*CMT[i] + b31*CMVA[i] + b32*CMVO[i] 
    y[i] ~ dnorm(mu[i], tau)
  }
  b0 ~ dnorm(0, 0.0001)
  b1 ~ dnorm(0, 0.0001)
  b2 ~ dnorm(0, 0.0001)
  b3 ~ dnorm(0, 0.0001)
  b4 ~ dnorm(0, 0.0001)
  b5 ~ dnorm(0, 0.0001)
  b6 ~ dnorm(0, 0.0001)
  b7 ~ dnorm(0, 0.0001)
  b8 ~ dnorm(0, 0.0001)
  b9 ~ dnorm(0, 0.0001)
  b10 ~ dnorm(0, 0.0001)
  b11 ~ dnorm(0, 0.0001)
  b12 ~ dnorm(0, 0.0001)
  b13 ~ dnorm(0, 0.0001)
  b14 ~ dnorm(0, 0.0001)
  b15 ~ dnorm(0, 0.0001)
  b16 ~ dnorm(0, 0.0001)
  b17 ~ dnorm(0, 0.0001)
  b18 ~ dnorm(0, 0.0001)
  b19 ~ dnorm(0, 0.0001)
  b20 ~ dnorm(0, 0.0001)
  b21 ~ dnorm(0, 0.0001)
  b22 ~ dnorm(0, 0.0001)
  b24 ~ dnorm(0, 0.0001)
  b15 ~ dnorm(0, 0.0001)
  b26 ~ dnorm(0, 0.0001)
  b27 ~ dnorm(0, 0.0001)
  b28 ~ dnorm(0, 0.0001)
  b29 ~ dnorm(0, 0.0001)
  b30 ~ dnorm(0, 0.0001)
  b31 ~ dnorm(0, 0.0001)
  b32 ~ dnorm(0, 0.0001)
  tau ~ dgamma(0.01, 0.01)
  s <- 1 / sqrt(tau)          
  }"


# initsList = list(list("b0"=mean(train$price), "b1"=0, "b2"=0, "b3"=0,"b4"=0,"b5"=0,"b6"=0,
#                       "b7"=0,"b8"=0,"b9"=0,"b10"=0,"b11"=0,"b12"=0,"b13"=0,"b14"=0,"b15"=0,"b16"=0,"b17"=0,"b18"=0,
#                       "b19"=0,"b20"=0,"b21"=0,"b22"=0,"b23"=0,"b24"=0,"b25"=0,"b26"=0,"b27"=0,"b28"=0,"b29"=0,"b30"=0,
#                       "b31"=0,"b32"=0,"sigma"=sd(train$price)), 
#                  list("b0"=mean(train$price), "b1"=rnorm(1,50,5), "b2"=0, "b3"=0,"b4"=0,"b5"=0,"b6"=0,
#                       "b7"=0,"b8"=0,"b9"=0,"b10"=0,"b11"=0,"b12"=0,"b13"=0,"b14"=0,"b15"=0,"b16"=0,"b17"=0,"b18"=0,
#                       "b19"=0,"b20"=0,"b21"=0,"b22"=0,"b23"=0,"b24"=0,"b25"=0,"b26"=0,"b27"=0,"b28"=0,"b29"=0,"b30"=0,
#                       "b31"=0,"b32"=0,"sigma"=sd(train$price)), 
#                  
#                  
#                  
#                  
#                  
#                  
#                  list("b0"=rnorm(1,50,5),   "b1"=rnorm(1,-2,1), "b2"=rnorm(1,2,1), "sigma"=sd(nels$math)), 
#                  list("b0"=rnorm(1,50,5),   "b1"=rnorm(1,1,1), "b2"=rnorm(1,1,1),  "sigma"=runif(1,0,10)), 
#                  list("b0"=rnorm(1,50,6),   "b1"=rnorm(1,0,1), "b2"=rnorm(1,0,1),  "sigma"=runif(1,0,10)) 
#                  )
# 
# initsList = list(list("b0"=mean(nels$math), "b1"=0, "b2"=0, "b3"=0, "sigma"=sd(nels$math)), 
#                  list("b0"=rnorm(1,50,5),   "b1"=rnorm(1,-2,1), "b2"=rnorm(1,2,1), "b3"=.3, "sigma"=sd(nels$math)), 
#                  list("b0"=rnorm(1,50,5),   "b1"=rnorm(1,1,1), "b2"=rnorm(1,1,1),  "b3"=.5,  "sigma"=runif(1,0,10)), 
#                  list("b0"=rnorm(1,50,6),   "b1"=rnorm(1,0,1), "b2"=rnorm(1,0,1),  "b3"=-.3,  "sigma"=runif(1,0,10)) 
#                  )



```


```{r}
#delpoy the model
jags_1 <- jags.model(textConnection(model_1), data =dataList, n.chains=3,n.adapt=3)
update(jags_1, 100)
jags_sim_1 <- coda.samples(model = jags_sim_1, variable.names = c("b0", "b1", "b2","b3","b4",
                                                                  "b5","b6","b7","b8","b9","b10",
                                                                  "b11","b12","b13","b14","b15",
                                                                  "b16","b17","b18","b19","b20",
                                                                  "b21","b22","b23","b24","b25","b26","b27",
                                                                  "b28","b29","b30","b31","b32","s"), n.iter = 100)

summary(jags_sim_1)
```


```{r}
#first jags model 
mod1_string <- " model{
    for(i in 1:n){
        #Likelihood
        y[i] ~ dnorm(mu[i], prec)
        mu[i] = b0 + b1 * TA[i] +b2 * TM[i] +b3*TS[i]+ b4* Mileage[i] + b5*FD[i]  + b6 * FH[i] + b7 +FP[i] + b8 * tax[i] + b9* mpg[i] + b10 * engineSize[i] + b11*Y2008[i] +  b12*Y2009[i] + b13*Y2010[i] + b14*Y2011[i] + b15*Y2012[i] + b16*Y2013[i] + b17*Y2014[i] + b18*Y2015[i] + b19*Y2016[i]
    + b20*Y2017[i] + b21*Y2018[i] + b22*Y2019[i] + b23*Y2020[i] +  b24 * Audi[i] + b25 * BMW[i] + b26* Ford[i] + b27 * Hyundai[i] + b28 * Mercedes[i] + b29* Skoda[i] + b30* Toyota[i]+ b31 * Vauxhall[i] + b32 * Volkswagen[i] 
                }            
    for(i in 1:2){
        #Prior for coefficients
        b[i] ~ dnorm(0.0, 1.0/1.0e6)
    }
        #Prior for left, unaccounted variance
        prec ~ dgamma(5/2.0, 5*10.0/2.0)
        sig2 = 1.0 / prec
        sig = sqrt(sig2)
}"

```





```{r}
# REGRESSION VARIABLES
predictors = c('year','transmission', 'mileage', 'engineSize', 'Car.Make')
dependent = "price"
dataList = list(
  x = zx,            # Predictor Variables
  y = as.vector(zy), # Dependent variable
  N = length(y),     # Number of data points
  K = ncol(x)        # Number of predictors
)

```


```{r}
#qqnorm(model_full, main="Full Model") 
#qqline(model_full)

```

```{r}
#backward 
models <- regsubsets(price~., data = df, nvmax = 9,
                     method = "backward")
summary(models)
```

```{r}
qjaw <- lm(price ~ year +  + I(age ^ 2), data = jaws)
summary(qjaw)
plot(jaws)
grid <- seq(0, 60, 0.01)
lines(grid, predict(qjaw, data.frame(age = grid)), col = "red")

```

