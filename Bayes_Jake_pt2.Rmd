---
title: "Jake_Bayes_Project"
author: "Jake Lieberfarb"
date: "11/7/2021"
output: html_document
---


```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = 'markup', message = F)
knitr::opts_chunk$set(warning = F, results = 'hide', message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r basic, include=F}
# use this function to conveniently load libraries and work smoothly with knitting
# can add quietly=T option to the require() function
loadPkg = function(pkg, character.only = FALSE) { 
  if (!character.only) { pkg <- as.character(substitute(pkg)) }
  pkg <- ifelse(!character.only, as.character(substitute(pkg)) , pkg)  
  if (!require(pkg,character.only=T, quietly =T)) {  install.packages(substitute(pkg),dep=T); if(!require(pkg,character.only=T)) stop("Package not found") } 
}
loadPkg(knitr)

# unload/detact package when done using it
unloadPkg = function(pkg, character.only = FALSE) { 
  if(!character.only) { pkg <- as.character(substitute(pkg)) } 
  search_item <- paste("package", pkg,sep = ":") 
  while(search_item %in% search()) { detach(search_item, unload = TRUE, character.only = TRUE) } 
}
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
loadPkg(mltools)
loadPkg(data.table)
```

```{r}
#import necessary Linear model data
set.seed(42)
data_df <- read.csv("/Users/jakelieberfarb/Desktop/college/Grad (2021-2022)/Bayesian DS/Project/Bayesian_Computing_Final_Project/Linear_model_data.csv")
data_df$id <- sample(98439, size = nrow(data_df), replace = TRUE)
drop <- c("X")
data_df = data_df[,!(names(data_df) %in% drop)]
head(data_df)
```


```{r}
#turn categorical values into numerics 
# data_clean_2 <- sapply(data_clean, unclass)
# df <- as.data.frame(data_clean_2)
# df$model <- as.factor(df$model)
# df$price <- as.factor(df$price)
# df$transmission <- as.factor(df$transmission)
# df$fuelType <- as.factor(df$fuelType)
# df$Car.Make <- as.factor(df$Car.Make)
# df$price <- as.numeric(df$price)
# head(df)
```


```{r}
# Linear Model 
set.seed(42)
#pick model from stepwise regression 
library(tidyverse)
library(caret)
library(leaps)
data_df$year_2008 <- as.factor(data_df$year_2008)
data_df$year_2009 <- as.factor(data_df$year_2009)
data_df$year_2010 <- as.factor(data_df$year_2010)
data_df$year_2011 <- as.factor(data_df$year_2011)
data_df$year_2012 <- as.factor(data_df$year_2012)
data_df$year_2013 <- as.factor(data_df$year_2013)
data_df$year_2014 <- as.factor(data_df$year_2014)
data_df$year_2015 <- as.factor(data_df$year_2015)
data_df$year_2016 <- as.factor(data_df$year_2016)
data_df$year_2017 <- as.factor(data_df$year_2017)
data_df$year_2018 <- as.factor(data_df$year_2018)
data_df$year_2019 <- as.factor(data_df$year_2019)
data_df$year_2020 <- as.factor(data_df$year_2020)
data_df$transmission_Automatic <- as.factor(data_df$transmission_Automatic)
data_df$transmission_Manual <- as.factor(data_df$transmission_Manual)
data_df$transmission_Semi.Auto <- as.factor(data_df$transmission_Semi.Auto)
data_df$fuelType_Diesel <- as.factor(data_df$fuelType_Diesel)
data_df$fuelType_Hybrid <- as.factor(data_df$fuelType_Hybrid)
data_df$fuelType_Petrol <- as.factor(data_df$fuelType_Petrol)
data_df$Car.Make_Audi <- as.factor(data_df$Car.Make_Audi)
data_df$Car.Make_BMW <- as.factor(data_df$Car.Make_BMW)
data_df$Car.Make_Ford <- as.factor(data_df$Car.Make_Ford)
data_df$Car.Make_Hyundai <- as.factor(data_df$Car.Make_Hyundai)
data_df$Car.Make_Mercedes <- as.factor(data_df$Car.Make_Mercedes)
data_df$Car.Make_Skoda <- as.factor(data_df$Car.Make_Skoda)
data_df$Car.Make_Toyota <- as.factor(data_df$Car.Make_Toyota)
data_df$Car.Make_Vauxhall <- as.factor(data_df$Car.Make_Vauxhall)
data_df$Car.Make_Volkswagen <- as.factor(data_df$Car.Make_Volkswagen)
# split linear data into train and test
smp_size <- floor(0.75 * nrow(data_df)) # 75/25 for train/test split 

train_ind <- sample(seq_len(nrow(data_df)), size = smp_size)
train <- data_df[train_ind, ]
test <- data_df[-train_ind, ]
head(data_df)

```

```{r}
#quick descriptive stats on price value
ybar<- mean(data_df$price)
std <- sd(data_df$price)
s2  <- var(data_df$price)
n   <- length(data_df$price)
descriptive <- c(n,ybar,std,s2)
names(descriptive) <- c("N","Ybar","std","s^2")
descriptive
```






```{r}
# built full LM frequentist model
model_full <- lm(price~. , data = train)
summary(model_full)
model_full_vif = faraway::vif(model_full)
#none of the coefficients have a significantly high vif factor
model_full_vif
#names(model_full)
```

```{r}
#loadPkg(BAS)
# Obtain residuals and n
#still not working
test_x <- test[, !names(test) %in% c("price")] 
y_pred= predict(model_full, test_x)

resid_full= test$price-y_pred
n = length(resid)
# Calculate MSE
MSE = 1/ (n - 2) * sum((resid_full ^ 2))
options(digits=15) # make sure MSE is listed out completely
print('MSE is')
MSE
plot(resid_full, x_lab= 'MSE', main='residual Plot of Full Frequentist Model')
par(mfrow = c(2, 2))
plot(model_full)
```

```{r}
#R^2 model
loadPkg("leaps")
visbest_adjr <- regsubsets(price~. , data = data_df, nbest = 2, method = "exhaustive",really.big=T) 
plot(visbest_adjr, scale = "adjr2", main = "Adjusted R^2")
summaryRegForward = summary(visbest_adjr)
#r_sqr_model <- lm(price~ year+transmission+mileage+engineSize+Car.Make, data = df)
#summary(r_sqr_model)
#resid_r_sqr = residuals(r_sqr_model)
#n = length(resid_r_sqr)

# Calculate MSE
#MSE = 1/ (n - 2) * sum((resid_r_sqr ^ 2))
#print('MSE for frequentist r^2 is')
#MSE
#plot(resid_r_sqr)
```

```{r}
#built adjusted R^2 model 
# issue here bc when I built the model based off the ideal adj R^2 model it returned a much lower adjr^2 value
adj_model <- lm(price~ year_2018+year_2019+transmission_Automatic+mileage+fuelType_Hybrid+fuelType_Petrol+
                   Car.Make_Ford+Car.Make_Hyundai+Car.Make_Vauxhall , data = data_df)
summary(adj_model)
adj_model_vif = faraway::vif(adj_model)
#none of the coefficients have a significantly high vif factor
adj_model_vif
```



```{r}
# Standardize data
train_2 <- train %>% mutate_at(c("price", "mileage", "tax", "mpg", "engineSize" ), ~(scale(.) %>% as.vector))
head(train_2)
nrow(train)
train <- sample_n(train, 100)
```

```{r}
# jags model 
library(rjags)
y=as.vector(train$price)
y_2008=as.vector(train$year_2008)
y_2009=as.vector(train$year_2009)
y_2010=as.vector(train$year_2010)
y_2011=as.vector(train$year_2011)
y_2012=as.vector(train$year_2012)
y_2013=as.vector(train$year_2013)
y_2014=as.vector(train$year_2014)
y_2015=as.vector(train$year_2015)
y_2016=as.vector(train$year_2016)
y_2017=as.vector(train$year_2017)
y_2018=as.vector(train$year_2018)
y_2019=as.vector(train$year_2019)
y_2020=as.vector(train$year_2020)
TA=as.vector(train$transmission_Automatic)
TM=as.vector(train$transmission_Manual)
TS=as.vector(train$transmission_Semi.Auto)
mileage=as.vector(train$mileage)
FTD=as.vector(train$fuelType_Diesel)
FTH=as.vector(train$fuelType_Hybrid)
FTP=as.vector(train$fuelType_Petrol)
tax=as.vector(train$tax)
mpg=as.vector(train$mpg)
ES=as.vector(train$engineSize)
CMA=as.vector(train$Car.Make_Audi)
CMB=as.vector(train$Car.Make_BMW)
CMF=as.vector(train$Car.Make_Ford)
CMH=as.vector(train$Car.Make_Hyundai)
CMM=as.vector(train$Car.Make_Mercedes)
CMS=as.vector(train$Car.Make_Skoda)
CMT=as.vector(train$Car.Make_Toyota)
CMVA=as.vector(train$Car.Make_Vauxhall)
CMVO=as.vector(train$Car.Make_Volkswagen)
N=length(train$price)


dataList <- list("y"=y, "y_2008"= y_2008, "y_2009"=y_2009, "y_2010"=y_2010, "y_2011"=y_2011, 
                 "y_2012"=y_2012, "y_2013"=y_2013, "y_2014"=y_2014, "y_2015"=y_2015, "y_2016"=y_2016, 
                 "y_2017"=y_2017, "y_2018"=y_2018, "y_2019"=y_2019, "y_2020"=y_2020, 
                 "TA"=TA, "TM"=TM, "TS"=TS,"mileage"=mileage, "FTD"=FTD, "FTH"=FTH, "FTP"=FTP, "tax"=tax, 
                 "mpg"=mpg, "ES"=ES, "CMA"=CMA, "CMB"=CMB, "CMF"=CMF, "CMH"=CMH, "CMM"=CMM, "CMS"=CMS, 
                 "CMT"=CMT, "CMVA"=CMVA, "CMVO"=CMVO, "N"=N)
```


```{r}
model_1 <- "model{
  for(i in 1:N){
    y[i] ~ dnorm(b0 + b1 * y_2008[i] + b2 * y_2009[i] +b3*y_2010[i]+ b4* y_2011[i] + b5*y_2012[i]  + b6 * y_2013[i] +
      b7* y_2014[i] + b8*y_2015[i] + b9* y_2016[i] + b10 * y_2017[i] + b11*y_2018[i]
    + b12*y_2019[i] + b13*y_2020[i] + b14*TA[i] + b15*TM[i] + b16*TS[i]
    + b17*mileage[i] + b18*FTD[i] + b19*FTH[i] + b20*FTP[i] + b21*tax[i] 
    + b22*mpg[i] + b23*ES[i] + b24*CMA[i] + b25*CMB[i] + b26*CMF[i] + b27*CMH[i] 
    + b28*CMM[i] + b29*CMS[i] + b30*CMT[i] + b31*CMVA[i] + b32*CMVO[i], invsigma2)
  }
  b0 ~ dnorm(0, 0.0001)
  b1 ~ dnorm(0, 0.0001)
  b2 ~ dnorm(0, 0.0001)
  b3 ~ dnorm(0, 0.0001)
  b4 ~ dnorm(0, 0.0001)
  b5 ~ dnorm(0, 0.0001)
  b6 ~ dnorm(0, 0.0001)
  b7 ~ dnorm(0, 0.0001)
  b8 ~ dnorm(0, 0.0001)
  b9 ~ dnorm(0, 0.0001)
  b10 ~ dnorm(0, 0.0001)
  b11 ~ dnorm(0, 0.0001)
  b12 ~ dnorm(0, 0.0001)
  b13 ~ dnorm(0, 0.0001)
  b14 ~ dnorm(0, 0.0001)
  b15 ~ dnorm(0, 0.0001)
  b16 ~ dnorm(0, 0.0001)
  b17 ~ dnorm(0, 0.0001)
  b18 ~ dnorm(0, 0.0001)
  b19 ~ dnorm(0, 0.0001)
  b20 ~ dnorm(0, 0.0001)
  b21 ~ dnorm(0, 0.0001)
  b22 ~ dnorm(0, 0.0001)
  b23 ~ dnorm(0, 0.0001)
  b24 ~ dnorm(0, 0.0001)
  b25 ~ dnorm(0, 0.0001)
  b26 ~ dnorm(0, 0.0001)
  b27 ~ dnorm(0, 0.0001)
  b28 ~ dnorm(0, 0.0001)
  b29 ~ dnorm(0, 0.0001)
  b30 ~ dnorm(0, 0.0001)
  b31 ~ dnorm(0, 0.0001)
  b32 ~ dnorm(0, 0.0001)
  invsigma2 ~ dgamma(.01, .01)
  s <- sqrt(pow(invsigma2, -1))         
  }"
```


```{r}
#delpoy the model
loadPkg(runjags)
jags_1 <- jags.model(textConnection(model_1), n.chains = 3, data =dataList, quiet=TRUE)
```

```{r}
update(jags_1, 10)
jags_sim_1 <- coda.samples(model = jags_sim_1, variable.names = c("b0", "b1", "b2","b3","b4",
                                                                  "b5","b6","b7","b8","b9","b10",
                                                                  "b11","b12","b13","b14","b15",
                                                                  "b16","b17","b18","b19","b20",
                                                                  "b21","b22","b23","b24","b25","b26","b27",
                                                                  "b28","b29","b30","b31","b32","s"), n.iter = 10)

summary(jags_sim_1)
```


```{r}
#first jags model 
mod1_string <- " model{
    for(i in 1:n){
        #Likelihood
        y[i] ~ dnorm(mu[i], prec)
        mu[i] = b0 + b1 * TA[i] +b2 * TM[i] +b3*TS[i]+ b4* Mileage[i] + b5*FD[i]  + b6 * FH[i] + b7 +FP[i] + b8 * tax[i] + b9* mpg[i] + b10 * engineSize[i] + b11*Y2008[i] +  b12*Y2009[i] + b13*Y2010[i] + b14*Y2011[i] + b15*Y2012[i] + b16*Y2013[i] + b17*Y2014[i] + b18*Y2015[i] + b19*Y2016[i]
    + b20*Y2017[i] + b21*Y2018[i] + b22*Y2019[i] + b23*Y2020[i] +  b24 * Audi[i] + b25 * BMW[i] + b26* Ford[i] + b27 * Hyundai[i] + b28 * Mercedes[i] + b29* Skoda[i] + b30* Toyota[i]+ b31 * Vauxhall[i] + b32 * Volkswagen[i] 
                }            
    for(i in 1:2){
        #Prior for coefficients
        b[i] ~ dnorm(0.0, 1.0/1.0e6)
    }
        #Prior for left, unaccounted variance
        prec ~ dgamma(5/2.0, 5*10.0/2.0)
        sig2 = 1.0 / prec
        sig = sqrt(sig2)
}"

```





```{r}
# REGRESSION VARIABLES
predictors = c('year','transmission', 'mileage', 'engineSize', 'Car.Make')
dependent = "price"
dataList = list(
  x = zx,            # Predictor Variables
  y = as.vector(zy), # Dependent variable
  N = length(y),     # Number of data points
  K = ncol(x)        # Number of predictors
)

```


```{r}
#qqnorm(model_full, main="Full Model") 
#qqline(model_full)

```

```{r}
#backward 
models <- regsubsets(price~., data = df, nvmax = 9,
                     method = "backward")
summary(models)
```

```{r}
qjaw <- lm(price ~ year +  + I(age ^ 2), data = jaws)
summary(qjaw)
plot(jaws)
grid <- seq(0, 60, 0.01)
lines(grid, predict(qjaw, data.frame(age = grid)), col = "red")

```

