---
title: "Bayesian Linear Regression Model"
author: "Jake Lieberfarb"
date: "12/8/2021"
output: html_document
---


```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = 'markup', message = F)
knitr::opts_chunk$set(warning = F, results = 'hide', message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r basic, include=F}
# use this function to conveniently load libraries and work smoothly with knitting
# can add quietly=T option to the require() function
loadPkg = function(pkg, character.only = FALSE) { 
  if (!character.only) { pkg <- as.character(substitute(pkg)) }
  pkg <- ifelse(!character.only, as.character(substitute(pkg)) , pkg)  
  if (!require(pkg,character.only=T, quietly =T)) {  install.packages(substitute(pkg),dep=T); if(!require(pkg,character.only=T)) stop("Package not found") } 
}
loadPkg(knitr)

# unload/detact package when done using it
unloadPkg = function(pkg, character.only = FALSE) { 
  if(!character.only) { pkg <- as.character(substitute(pkg)) } 
  search_item <- paste("package", pkg,sep = ":") 
  while(search_item %in% search()) { detach(search_item, unload = TRUE, character.only = TRUE) } 
}
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
loadPkg(mltools)
loadPkg(data.table)
```

```{r}
#import necessary Linear model data
set.seed(42)
data_df <- read.csv("Data/uk_used_cars.csv")
data_df$id <- sample(98439, size = nrow(data_df), replace = TRUE)
drop <- c("X")
data_df = data_df[,!(names(data_df) %in% drop)]
head(data_df)
```

```{r}
# Linear Model 
set.seed(42)
#pick model from stepwise regression 
library(tidyverse)
library(caret)
library(leaps)
data_df$year_2008 <- as.factor(data_df$year_2008)
data_df$year_2009 <- as.factor(data_df$year_2009)
data_df$year_2010 <- as.factor(data_df$year_2010)
data_df$year_2011 <- as.factor(data_df$year_2011)
data_df$year_2012 <- as.factor(data_df$year_2012)
data_df$year_2013 <- as.factor(data_df$year_2013)
data_df$year_2014 <- as.factor(data_df$year_2014)
data_df$year_2015 <- as.factor(data_df$year_2015)
data_df$year_2016 <- as.factor(data_df$year_2016)
data_df$year_2017 <- as.factor(data_df$year_2017)
data_df$year_2018 <- as.factor(data_df$year_2018)
data_df$year_2019 <- as.factor(data_df$year_2019)
data_df$year_2020 <- as.factor(data_df$year_2020)
data_df$transmission_Automatic <- as.factor(data_df$transmission_Automatic)
data_df$transmission_Manual <- as.factor(data_df$transmission_Manual)
data_df$transmission_Semi.Auto <- as.factor(data_df$transmission_Semi.Auto)
data_df$fuelType_Diesel <- as.factor(data_df$fuelType_Diesel)
data_df$fuelType_Hybrid <- as.factor(data_df$fuelType_Hybrid)
data_df$fuelType_Petrol <- as.factor(data_df$fuelType_Petrol)
data_df$Car.Make_Audi <- as.factor(data_df$Car.Make_Audi)
data_df$Car.Make_BMW <- as.factor(data_df$Car.Make_BMW)
data_df$Car.Make_Ford <- as.factor(data_df$Car.Make_Ford)
data_df$Car.Make_Hyundai <- as.factor(data_df$Car.Make_Hyundai)
data_df$Car.Make_Mercedes <- as.factor(data_df$Car.Make_Mercedes)
data_df$Car.Make_Skoda <- as.factor(data_df$Car.Make_Skoda)
data_df$Car.Make_Toyota <- as.factor(data_df$Car.Make_Toyota)
data_df$Car.Make_Vauxhall <- as.factor(data_df$Car.Make_Vauxhall)
data_df$Car.Make_Volkswagen <- as.factor(data_df$Car.Make_Volkswagen)
# split linear data into train and test
smp_size <- floor(0.75 * nrow(data_df)) # 75/25 for train/test split 

train_ind <- sample(seq_len(nrow(data_df)), size = smp_size)
train <- data_df[train_ind, ]
test <- data_df[-train_ind, ]
head(data_df)
```

```{r}
#quick descriptive stats on price value
ybar<- mean(data_df$price)
std <- sd(data_df$price)
s2  <- var(data_df$price)
n   <- length(data_df$price)
descriptive <- c(n,ybar,std,s2)
names(descriptive) <- c("N","Ybar","std","s^2")
descriptive
```






```{r}
# built full LM frequentist model
model_full <- lm(price~. , data = train)
summary(model_full)
model_full_vif = faraway::vif(model_full)
#none of the coefficients have a significantly high vif factor
model_full_vif
#names(model_full)
```

```{r}
#loadPkg(BAS)
# Obtain residuals and n
#still not working
test_x <- test[, !names(test) %in% c("price")] 
y_pred= predict(model_full, test_x)

resid_full= test$price-y_pred
n = length(resid)
# Calculate MSE
MSE = 1/ (n - 2) * sum((resid_full ^ 2))
options(digits=15) # make sure MSE is listed out completely
print('MSE is')
MSE
plot(resid_full, x_lab= 'MSE', main='residual Plot of Full Frequentist Model')
par(mfrow = c(2, 2))
plot(model_full)
```

```{r}
#R^2 model
# loadPkg("leaps")
# visbest_adjr <- regsubsets(price~. , data = data_df, nbest = 2, method = "exhaustive",really.big=T) 
# plot(visbest_adjr, scale = "adjr2", main = "Adjusted R^2")
# summaryRegForward = summary(visbest_adjr)
#r_sqr_model <- lm(price~ year+transmission+mileage+engineSize+Car.Make, data = df)
#summary(r_sqr_model)
#resid_r_sqr = residuals(r_sqr_model)
#n = length(resid_r_sqr)

# Calculate MSE
#MSE = 1/ (n - 2) * sum((resid_r_sqr ^ 2))
#print('MSE for frequentist r^2 is')
#MSE
#plot(resid_r_sqr)
```

```{r}
#built adjusted R^2 model 
# # issue here bc when I built the model based off the ideal adj R^2 model it returned a much lower adjr^2 value
# adj_model <- lm(price~ year_2018+year_2019+transmission_Automatic+mileage+fuelType_Hybrid+fuelType_Petrol+
#                    Car.Make_Ford+Car.Make_Hyundai+Car.Make_Vauxhall , data = data_df)
# summary(adj_model)
# adj_model_vif = faraway::vif(adj_model)
# #none of the coefficients have a significantly high vif factor
# adj_model_vif
```

```{r}
library(mltools)
library(data.table)
data_df$year <- as.factor(data_df$year)
train<- as.data.frame(one_hot(as.data.table(data_df)))
train
```


```{r}
# Standardize data
train_2 <- train %>% mutate_at(c("price", "mileage", "tax", "mpg", "engineSize" ), ~(scale(.) %>% as.vector))
head(train_2)
nrow(train)
#train <- sample_n(train, 100)
```

```{r}
train$y
```


```{r}
# jags model 
library(rjags)

y=train$price
y_2008=train$year_2008
y_2009=train$year_2009
y_2010=train$year_2010
y_2011=train$year_2011
y_2012=train$year_2012
y_2013=train$year_2013
y_2014=train$year_2014
y_2015=train$year_2015
y_2016=train$year_2016
y_2017=train$year_2017
y_2018=train$year_2018
y_2019=train$year_2019
y_2020=train$year_2020
TA=train$transmission_Automatic
TM=train$transmission_Manual
TS=train$`transmission_Semi-Auto`
mileage=train$mileage
FTD=train$fuelType_Diesel
FTH=train$fuelType_Hybrid
FTP=train$fuelType_Petrol
tax=train$tax
mpg=train$mpg
ES=train$engineSize
CMA=train$Car.Make_Audi
CMB=train$Car.Make_BMW
CMF=train$Car.Make_Ford
CMH=train$Car.Make_Hyundai
CMM=train$Car.Make_Mercedes
CMS=train$Car.Make_Skoda
CMT=train$Car.Make_Toyota
CMVA=train$Car.Make_Vauxhall
CMVO=train$Car.Make_Volkswagen
N=length(train$price)


dataList <- list("y"=y, "y_2008"= y_2008, "y_2009"=y_2009, "y_2010"=y_2010, "y_2011"=y_2011, 
                 "y_2012"=y_2012, "y_2013"=y_2013, "y_2014"=y_2014, "y_2015"=y_2015, "y_2016"=y_2016, 
                 "y_2017"=y_2017, "y_2018"=y_2018, "y_2019"=y_2019, "y_2020"=y_2020,"TA"=TA, "TM"=TM,
                 "TS"=TS,"mileage"=mileage, "FTD"=FTD, "FTH"=FTH, "FTP"=FTP, "tax"=tax, 
                 "mpg"=mpg, "ES"=ES, "CMA"=CMA, "CMB"=CMB, "CMF"=CMF, "CMH"=CMH, "CMM"=CMM, "CMS"=CMS, 
                 "CMT"=CMT, "CMVA"=CMVA, "CMVO"=CMVO, "N"=N)
```


```{r}
model_1 <- "model{
  for(i in 1:N){
    y[i] ~ dnorm(mu[i], invsigma2)
    
    mu[i] <- b0 + b1*y_2008[i] + b2*y_2009[i] +b3*y_2010[i]+ b4* y_2011[i] + b5*y_2012[i]  + b6 * y_2013[i] +
      b7*y_2014[i] + b8*y_2015[i] + b9*y_2016[i] + b10*y_2017[i] + b11*y_2018[i]
    + b12*y_2019[i] + b13*y_2020[i]
  }
  b0 ~ dnorm(0, 0.0001)
  b1 ~ dnorm(0, 0.0001)
  b2 ~ dnorm(0, 0.0001)
  b3 ~ dnorm(0, 0.0001)
  b4 ~ dnorm(0, 0.0001)
  b5 ~ dnorm(0, 0.0001)
  b6 ~ dnorm(0, 0.0001)
  b7 ~ dnorm(0, 0.0001)
  b8 ~ dnorm(0, 0.0001)
  b9 ~ dnorm(0, 0.0001)
  b10 ~ dnorm(0, 0.0001)
  b11 ~ dnorm(0, 0.0001)
  b12 ~ dnorm(0, 0.0001)
  b13 ~ dnorm(0, 0.0001)
  
  invsigma2 ~ dgamma(.01, .01)
  s <- sqrt(pow(invsigma2, -1))         
  }"
```


```{r}
#delpoy the model
loadPkg(runjags)
require(rjags)
require(runjags)
jags_1 <- jags.model(textConnection(model_1), data =list(y=train$price,
y_2008=train$year_2008,
y_2009=train$year_2009,
y_2010=train$year_2010,
y_2011=train$year_2011,
y_2012=train$year_2012,
y_2013=train$year_2013,
y_2014=train$year_2014,
y_2015=train$year_2015,
y_2016=train$year_2016,
y_2017=train$year_2017,
y_2018=train$year_2018,
y_2019=train$year_2019,
y_2020=train$year_2020,
N=length(train$price)),  n.chains = 3, n.adapt=3)
```

```{r}
update(jags_1, 1000)
jags_sim_1 <- coda.samples(model = jags_1, variable.names = c("b0", "b1", "b2","b3","b4",
                                                                  "b5","b6","b7","b8","b9","b10",
                                                                  "b11","b12","b13","s"), n.iter = 1000)
summary(jags_sim_1)
```


```{r}
#check residuals of the model 
new_train <- subset(train, select = c('year_2008',
                                      'year_2009',
                                      'year_2010',
                                      'year_2011',
                                      'year_2012',
                                      'year_2013',
                                      'year_2014',
                                      'year_2015',
                                      'year_2016',
                                      'year_2017',
                                      'year_2018',
                                     'year_2019',
                                      'year_2020',
                                      "price"
                                      ))
price_csim <- as.mcmc(do.call(rbind, jags_sim_1))



```

```{r}
X <- data.matrix(new_train[1:13])
pm_params1= colMeans(price_csim)
yhat=-(1+  X[,c(1:13)] %*% pm_params1[1:13])
resid1= new_train$price - yhat
plot(resid1)

```

```{r}
MSE = 1/ (length(new_train) - 2) * sum((resid1 ^ 2))
options(digits=15) # make sure MSE is listed out completely
print('MSE is')
MSE
plot(resid1, x_lab= 'MSE', main='residual Plot of Full jags Model')
```

```{r}
plot(price_csim)

```

